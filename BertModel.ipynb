{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BertModel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPYPeO/hP/r9tkkrAd7nBa4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlirezaPNouri/BERTEmbedding/blob/main/BertModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIp-SS4UvBi9"
      },
      "source": [
        "\n",
        "Author: Alireza P. Nouri\n",
        "Advisor: prof. M. Shahriar hossain\n",
        "contact: apashamoham@miners.utep.edu\n",
        "Implementing feature exrtaction by BERT model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-Pj-Ebqu-qa",
        "outputId": "f449bb40-0297-4751-8dba-ea3b92a0c2b4"
      },
      "source": [
        "# to check if the GPU is ready to use\n",
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Efs36yprwA50",
        "outputId": "90533762-a9ce-4465-9baa-54bec38bbe88"
      },
      "source": [
        "# to tell pytorch that we are going to use GPU\n",
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqDeFtqnwhd5",
        "outputId": "49b8c4aa-adc2-4548-ddf8-0ea9add0ebe0"
      },
      "source": [
        "# download transformer package\n",
        "!pip install transformers"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.8.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxE4y1_axjrN"
      },
      "source": [
        "loading CoLA Dataset (The Corpus of Linguistic Acceptability) 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRM8CUtIx25F",
        "outputId": "ebb79a89-ed40-4fa2-de60-f1a270c41393"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoMQvIfOyHya",
        "outputId": "7cabc32d-4d29-4538-cf2c-68f7699673b6"
      },
      "source": [
        "# download the dataset as a zip file\n",
        "import wget\n",
        "import os\n",
        "\n",
        "print('Downloading dataset...')\n",
        "\n",
        "# The URL for the dataset zip file.\n",
        "url = 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'\n",
        "\n",
        "# Download the file (if we haven't already)\n",
        "if not os.path.exists('./cola_public_1.1.zip'):\n",
        "    wget.download(url, './cola_public_1.1.zip')\n",
        "print('Download is done!')"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading dataset...\n",
            "Download is done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBBJXDH8yiFv"
      },
      "source": [
        "# unzip the dataset\n",
        "if not os.path.exists('./cola_public/'):\n",
        "    !unzip cola_public_1.1.zip\n"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRdlKBp-zuqL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "1adb1f1a-3250-47fa-8014-33f4c1b947df"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"./cola_public/raw/in_domain_train.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 8,551\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_source</th>\n",
              "      <th>label</th>\n",
              "      <th>label_notes</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2389</th>\n",
              "      <td>l-93</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Angela characterized Shelly as a lifesaver.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5048</th>\n",
              "      <td>ks08</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>They're not finding it a stress being in the s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3133</th>\n",
              "      <td>l-93</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>Paul exhaled on Mary.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5955</th>\n",
              "      <td>c_13</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>I ordered if John drink his beer.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>625</th>\n",
              "      <td>bc01</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Press the stamp against the pad completely.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3542</th>\n",
              "      <td>ks08</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>They can very.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6915</th>\n",
              "      <td>m_02</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>This arch is supporting the weight of the tower.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2908</th>\n",
              "      <td>l-93</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>That new handle detaches easily.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5857</th>\n",
              "      <td>c_13</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The Brazilians pumped the oil across the river.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4191</th>\n",
              "      <td>ks08</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>It is a wooden desk.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     sentence_source  ...                                           sentence\n",
              "2389            l-93  ...        Angela characterized Shelly as a lifesaver.\n",
              "5048            ks08  ...  They're not finding it a stress being in the s...\n",
              "3133            l-93  ...                              Paul exhaled on Mary.\n",
              "5955            c_13  ...                  I ordered if John drink his beer.\n",
              "625             bc01  ...        Press the stamp against the pad completely.\n",
              "3542            ks08  ...                                     They can very.\n",
              "6915            m_02  ...   This arch is supporting the weight of the tower.\n",
              "2908            l-93  ...                   That new handle detaches easily.\n",
              "5857            c_13  ...    The Brazilians pumped the oil across the river.\n",
              "4191            ks08  ...                               It is a wooden desk.\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_Vr5CqJKs70"
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EltzyPpLEUv"
      },
      "source": [
        "Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zycdd5FRLIUk",
        "outputId": "eb2ca86d-7810-4fbb-f7c7-3c7b1efc0219"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYrtNYnqLQbv",
        "outputId": "88a45963-a0f3-44eb-c5c8-8c47aec651ce"
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Tokenized:  ['our', 'friends', 'won', \"'\", 't', 'buy', 'this', 'analysis', ',', 'let', 'alone', 'the', 'next', 'one', 'we', 'propose', '.']\n",
            "Token IDs:  [2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGn3SUQuvGjf",
        "outputId": "3c56d192-7965-40ed-fe44-18cce133c93e"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2132: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Token IDs: tensor([  101,  2256,  2814,  2180,  1005,  1056,  4965,  2023,  4106,  1010,\n",
            "         2292,  2894,  1996,  2279,  2028,  2057, 16599,  1012,   102,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CtRdX_PvfPq",
        "outputId": "01383c79-5d3c-4801-8b55-1a7f359b9d7e"
      },
      "source": [
        "print('Max sentence length: ', max([len(sen) for sen in input_ids]))\n"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOsWtPZMxfQM"
      },
      "source": [
        "Split the training and validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpxJP4PLxqYC"
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for\n",
        "# training\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 90% for training and 10% for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=2018, test_size=0.1)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1-DnaLOyE4F"
      },
      "source": [
        "Convert data to pytorch tensor\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXkEz7xkx7no",
        "outputId": "eb2a3a03-6f8b-4f08-faa9-4eb8dce995ff"
      },
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype \n",
        "# for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VP60r_yWzG3O"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "batch_size = 32 \n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-eq_MQ-zIZU"
      },
      "source": [
        "Training By BERT - output_hidden_states must be true if word embedding is the case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSIacJtbzdiG",
        "outputId": "e3c177c0-ab62-4f65-8eff-aead4f9b1cae"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = True, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fh5B4K1v1vvy",
        "outputId": "e391ca8d-e492-40b2-bc2d-4d93cac749c4"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsLyu_e4Og19"
      },
      "source": [
        "Optimizer and Learning Rate Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iS87rfWkOoc9"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPLk0t13Ots1"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppbPluHVQDMM"
      },
      "source": [
        "Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahrJPyphQA0l"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYrCxIOhQQRh"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvSGFE9bosAz"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFBSjiG1QTxb",
        "outputId": "742ded34-a077-4fdb-a491-0e948fce2299"
      },
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    embedding_layers = []\n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        # print(len(outputs))\n",
        "        # print(outputs[0]) the loss\n",
        "        # print(len(outputs[1])) the batches\n",
        "        # print(len(outputs[2])) the embedding layers\n",
        "        # import numpy as np\n",
        "        # print(np.shape(outputs[2]))--->(13,)\n",
        "        # print(np.shape(outputs[2][1])) --->torch.Size([32, 64, 768]) the embedding in the layer one\n",
        "        # print(np.shape(outputs[2][2]))--->torch.Size([32, 64, 768]) the embedding in the layer two\n",
        "        # print(len(outputs[2][3]))\n",
        "        loss = outputs[0]\n",
        "        \n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "  "
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:13.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:27.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:40.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:54.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:07.\n",
            "  Batch   240  of    241.    Elapsed: 0:01:21.\n",
            "\n",
            "  Average training loss: 0.49\n",
            "  Training epcoh took: 0:01:21\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:14.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:28.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:42.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:56.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:10.\n",
            "  Batch   240  of    241.    Elapsed: 0:01:24.\n",
            "\n",
            "  Average training loss: 0.30\n",
            "  Training epcoh took: 0:01:24\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:14.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:28.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:43.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:57.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:11.\n",
            "  Batch   240  of    241.    Elapsed: 0:01:26.\n",
            "\n",
            "  Average training loss: 0.19\n",
            "  Training epcoh took: 0:01:26\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:14.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:29.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:43.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:58.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:12.\n",
            "  Batch   240  of    241.    Elapsed: 0:01:27.\n",
            "\n",
            "  Average training loss: 0.13\n",
            "  Training epcoh took: 0:01:27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuuTLyfvSZOO",
        "outputId": "87742c91-ef0f-43e1-ea46-a4f7020c03a7"
      },
      "source": [
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "    #count = 0 # added by Ali\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        \n",
        "        logits = outputs[0]\n",
        "        # print(len(outputs))\n",
        "        # print(np.shape(outputs[1])) # all embedding layers data\n",
        "        # print(outputs[1][12]) # access to embedding vectors in layer 13\n",
        "        #count +=1 added by Ali\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "    #print(count)\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "  Validation took: 0:00:03\n",
            "27\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "r4SdcQNaU314",
        "outputId": "7d4f02b7-e93d-4157-abcc-e5e603f2db9c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjbHcq4QVCAL",
        "outputId": "045dd018-29f2-4d22-fa2f-8dc8a57378cd"
      },
      "source": [
        "import pandas as pd\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "#the same as the maxlen we used in the encoder_plus function\n",
        "MAX_LEN = max([len(sen) for sen in input_ids])\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"./cola_public/raw/out_of_domain_dev.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask) \n",
        "\n",
        "# Convert to tensors.\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 516\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QA5OeLalmRS",
        "outputId": "28f4bfd0-44fe-4320-b89e-a29136a8bc9a"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "  print(np.shape(outputs[0]))\n",
        "  print(np.shape(outputs[1][0]))\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 516 test sentences...\n",
            "torch.Size([32, 2])\n",
            "torch.Size([32, 64, 768])\n",
            "torch.Size([32, 2])\n",
            "torch.Size([32, 64, 768])\n",
            "torch.Size([32, 2])\n",
            "torch.Size([32, 64, 768])\n",
            "torch.Size([32, 2])\n",
            "torch.Size([32, 64, 768])\n",
            "torch.Size([32, 2])\n",
            "torch.Size([32, 64, 768])\n",
            "torch.Size([32, 2])\n",
            "torch.Size([32, 64, 768])\n",
            "torch.Size([32, 2])\n",
            "torch.Size([32, 64, 768])\n",
            "torch.Size([32, 2])\n",
            "torch.Size([32, 64, 768])\n",
            "torch.Size([32, 2])\n",
            "torch.Size([32, 64, 768])\n",
            "torch.Size([32, 2])\n",
            "torch.Size([32, 64, 768])\n",
            "torch.Size([32, 2])\n",
            "torch.Size([32, 64, 768])\n",
            "torch.Size([32, 2])\n",
            "torch.Size([32, 64, 768])\n",
            "torch.Size([32, 2])\n",
            "torch.Size([32, 64, 768])\n",
            "torch.Size([32, 2])\n",
            "torch.Size([32, 64, 768])\n",
            "torch.Size([32, 2])\n",
            "torch.Size([32, 64, 768])\n",
            "torch.Size([32, 2])\n",
            "torch.Size([32, 64, 768])\n",
            "torch.Size([4, 2])\n",
            "torch.Size([4, 64, 768])\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2PBa_UklqKw",
        "outputId": "8d4b4970-b0b8-45d3-edde-b8ea94ae2d54"
      },
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive samples: 354 of 516 (68.60%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBaovkgYlysZ",
        "outputId": "098c98d3-f638-4583-ed39-1b96599598ff"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  \n",
        "  # Calculate and store the coef for this batch.  \n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
        "  matthews_set.append(matthews)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdgjQo76l288",
        "outputId": "ade421b7-76c6-4446-d14a-5362cc75f2f7"
      },
      "source": [
        "matthews_set"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.049286405809014416,\n",
              " -0.21684543705982773,\n",
              " 0.4732058754737091,\n",
              " 0.30508307783296046,\n",
              " 0.4133804997216296,\n",
              " 0.7410010097502685,\n",
              " 0.4547940268270977,\n",
              " 0.0,\n",
              " 0.9165151389911681,\n",
              " 0.6952687917708212,\n",
              " 0.9229582069908973,\n",
              " 0.647150228929434,\n",
              " 0.8749672939989046,\n",
              " 0.8320502943378436,\n",
              " 0.1794871794871795,\n",
              " 0.7229437229437229,\n",
              " 0.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYtOFHTLl82e",
        "outputId": "29655bc0-fff0-4104-cdca-99d51838f3d9"
      },
      "source": [
        "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('MCC: %.3f' % mcc)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MCC: 0.524\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s18fKh3jnS3P"
      },
      "source": [
        "save and load the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNbQif_HnVMo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}