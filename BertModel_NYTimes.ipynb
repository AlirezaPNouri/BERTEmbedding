{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BertModel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNRcG/z3b05jIqWGwvlHger",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlirezaPNouri/BERTEmbedding/blob/main/BertModel_NYTimes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIp-SS4UvBi9"
      },
      "source": [
        "\n",
        "Author: Alireza P. Nouri\n",
        "Advisor: prof. M. Shahriar hossain\n",
        "contact: apashamoham@miners.utep.edu\n",
        "Implementing feature exrtaction by BERT model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-Pj-Ebqu-qa",
        "outputId": "f449bb40-0297-4751-8dba-ea3b92a0c2b4"
      },
      "source": [
        "# to check if the GPU is ready to use\n",
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Efs36yprwA50",
        "outputId": "90533762-a9ce-4465-9baa-54bec38bbe88"
      },
      "source": [
        "# to tell pytorch that we are going to use GPU\n",
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqDeFtqnwhd5",
        "outputId": "49b8c4aa-adc2-4548-ddf8-0ea9add0ebe0"
      },
      "source": [
        "# download transformer package\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.8.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxE4y1_axjrN"
      },
      "source": [
        "loading CoLA Dataset (The Corpus of Linguistic Acceptability) 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRM8CUtIx25F",
        "outputId": "ebb79a89-ed40-4fa2-de60-f1a270c41393"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoMQvIfOyHya",
        "outputId": "7cabc32d-4d29-4538-cf2c-68f7699673b6"
      },
      "source": [
        "# download the dataset as a zip file\n",
        "import wget\n",
        "import os\n",
        "\n",
        "print('Downloading dataset...')\n",
        "\n",
        "# The URL for the dataset zip file.\n",
        "url = 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'\n",
        "\n",
        "# Download the file (if we haven't already)\n",
        "if not os.path.exists('./cola_public_1.1.zip'):\n",
        "    wget.download(url, './cola_public_1.1.zip')\n",
        "print('Download is done!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading dataset...\n",
            "Download is done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBBJXDH8yiFv"
      },
      "source": [
        "# unzip the dataset\n",
        "if not os.path.exists('./cola_public/'):\n",
        "    !unzip cola_public_1.1.zip\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRdlKBp-zuqL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "1adb1f1a-3250-47fa-8014-33f4c1b947df"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"./cola_public/raw/in_domain_train.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 8,551\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_source</th>\n",
              "      <th>label</th>\n",
              "      <th>label_notes</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2389</th>\n",
              "      <td>l-93</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Angela characterized Shelly as a lifesaver.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5048</th>\n",
              "      <td>ks08</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>They're not finding it a stress being in the s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3133</th>\n",
              "      <td>l-93</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>Paul exhaled on Mary.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5955</th>\n",
              "      <td>c_13</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>I ordered if John drink his beer.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>625</th>\n",
              "      <td>bc01</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Press the stamp against the pad completely.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3542</th>\n",
              "      <td>ks08</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>They can very.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6915</th>\n",
              "      <td>m_02</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>This arch is supporting the weight of the tower.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2908</th>\n",
              "      <td>l-93</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>That new handle detaches easily.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5857</th>\n",
              "      <td>c_13</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The Brazilians pumped the oil across the river.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4191</th>\n",
              "      <td>ks08</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>It is a wooden desk.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     sentence_source  ...                                           sentence\n",
              "2389            l-93  ...        Angela characterized Shelly as a lifesaver.\n",
              "5048            ks08  ...  They're not finding it a stress being in the s...\n",
              "3133            l-93  ...                              Paul exhaled on Mary.\n",
              "5955            c_13  ...                  I ordered if John drink his beer.\n",
              "625             bc01  ...        Press the stamp against the pad completely.\n",
              "3542            ks08  ...                                     They can very.\n",
              "6915            m_02  ...   This arch is supporting the weight of the tower.\n",
              "2908            l-93  ...                   That new handle detaches easily.\n",
              "5857            c_13  ...    The Brazilians pumped the oil across the river.\n",
              "4191            ks08  ...                               It is a wooden desk.\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_Vr5CqJKs70"
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EltzyPpLEUv"
      },
      "source": [
        "Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zycdd5FRLIUk",
        "outputId": "eb2ca86d-7810-4fbb-f7c7-3c7b1efc0219"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYrtNYnqLQbv",
        "outputId": "88a45963-a0f3-44eb-c5c8-8c47aec651ce"
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Tokenized:  ['our', 'friends', 'won', \"'\", 't', 'buy', 'this', 'analysis', ',', 'let', 'alone', 'the', 'next', 'one', 'we', 'propose', '.']\n",
            "Token IDs:  [2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGn3SUQuvGjf",
        "outputId": "3c56d192-7965-40ed-fe44-18cce133c93e"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2132: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Token IDs: tensor([  101,  2256,  2814,  2180,  1005,  1056,  4965,  2023,  4106,  1010,\n",
            "         2292,  2894,  1996,  2279,  2028,  2057, 16599,  1012,   102,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CtRdX_PvfPq",
        "outputId": "01383c79-5d3c-4801-8b55-1a7f359b9d7e"
      },
      "source": [
        "print('Max sentence length: ', max([len(sen) for sen in input_ids]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOsWtPZMxfQM"
      },
      "source": [
        "Split the training and validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpxJP4PLxqYC"
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for\n",
        "# training\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 90% for training and 10% for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=2018, test_size=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1-DnaLOyE4F"
      },
      "source": [
        "Convert data to pytorch tensor\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXkEz7xkx7no",
        "outputId": "eb2a3a03-6f8b-4f08-faa9-4eb8dce995ff"
      },
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype \n",
        "# for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VP60r_yWzG3O"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "batch_size = 32 \n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-eq_MQ-zIZU"
      },
      "source": [
        "Training By BERT - output_hidden_states must be true if word embedding is the case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSIacJtbzdiG",
        "outputId": "e3c177c0-ab62-4f65-8eff-aead4f9b1cae"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = True, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fh5B4K1v1vvy",
        "outputId": "e391ca8d-e492-40b2-bc2d-4d93cac749c4"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsLyu_e4Og19"
      },
      "source": [
        "Optimizer and Learning Rate Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iS87rfWkOoc9"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPLk0t13Ots1"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppbPluHVQDMM"
      },
      "source": [
        "Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahrJPyphQA0l"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYrCxIOhQQRh"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvSGFE9bosAz"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFBSjiG1QTxb",
        "outputId": "742ded34-a077-4fdb-a491-0e948fce2299"
      },
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    embedding_layers = []\n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        # print(len(outputs))\n",
        "        # print(outputs[0]) the loss\n",
        "        # print(len(outputs[1])) the batches\n",
        "        # print(len(outputs[2])) the embedding layers\n",
        "        # import numpy as np\n",
        "        # print(np.shape(outputs[2]))--->(13,)\n",
        "        # print(np.shape(outputs[2][1])) --->torch.Size([32, 64, 768]) the embedding in the layer one\n",
        "        # print(np.shape(outputs[2][2]))--->torch.Size([32, 64, 768]) the embedding in the layer two\n",
        "        # print(len(outputs[2][3]))\n",
        "        loss = outputs[0]\n",
        "        \n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:13.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:27.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:40.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:54.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:07.\n",
            "  Batch   240  of    241.    Elapsed: 0:01:21.\n",
            "\n",
            "  Average training loss: 0.49\n",
            "  Training epcoh took: 0:01:21\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:14.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:28.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:42.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:56.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:10.\n",
            "  Batch   240  of    241.    Elapsed: 0:01:24.\n",
            "\n",
            "  Average training loss: 0.30\n",
            "  Training epcoh took: 0:01:24\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:14.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:28.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:43.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:57.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:11.\n",
            "  Batch   240  of    241.    Elapsed: 0:01:26.\n",
            "\n",
            "  Average training loss: 0.19\n",
            "  Training epcoh took: 0:01:26\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:14.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:29.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:43.\n",
            "  Batch   160  of    241.    Elapsed: 0:00:58.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:12.\n",
            "  Batch   240  of    241.    Elapsed: 0:01:27.\n",
            "\n",
            "  Average training loss: 0.13\n",
            "  Training epcoh took: 0:01:27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuuTLyfvSZOO",
        "outputId": "87742c91-ef0f-43e1-ea46-a4f7020c03a7"
      },
      "source": [
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "    #count = 0 # added by Ali\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        \n",
        "        logits = outputs[0]\n",
        "        # print(len(outputs))\n",
        "        # print(np.shape(outputs[1])) # all embedding layers data\n",
        "        # print(outputs[1][12]) # access to embedding vectors in layer 13\n",
        "        #count +=1 added by Ali\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "    #print(count)\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "  Validation took: 0:00:03\n",
            "27\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "r4SdcQNaU314",
        "outputId": "7d4f02b7-e93d-4157-abcc-e5e603f2db9c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjbHcq4QVCAL",
        "outputId": "045dd018-29f2-4d22-fa2f-8dc8a57378cd"
      },
      "source": [
        "import pandas as pd\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "#the same as the maxlen we used in the encoder_plus function\n",
        "MAX_LEN = max([len(sen) for sen in input_ids])\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"./cola_public/raw/out_of_domain_dev.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask) \n",
        "\n",
        "# Convert to tensors.\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 516\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QA5OeLalmRS",
        "outputId": "28f4bfd0-44fe-4320-b89e-a29136a8bc9a"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "  print(np.shape(outputs[0]))\n",
        "  print(np.shape(outputs[1][0]))\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 516 test sentences...\n",
            "torch.Size([32, 2])\n",
            "torch.Size([32, 64, 768])\n",
            "torch.Size([32, 2])\n",
            "torch.Size([32, 64, 768])\n",
            "torch.Size([32, 2])\n",
            "torch.Size([32, 64, 768])\n",
            "torch.Size([32, 2])\n",
            "torch.Size([32, 64, 768])\n",
            "torch.Size([32, 2])\n",
            "torch.Size([32, 64, 768])\n",
            "torch.Size([32, 2])\n",
            "torch.Size([32, 64, 768])\n",
            "torch.Size([32, 2])\n",
            "torch.Size([32, 64, 768])\n",
            "torch.Size([32, 2])\n",
            "torch.Size([32, 64, 768])\n",
            "torch.Size([32, 2])\n",
            "torch.Size([32, 64, 768])\n",
            "torch.Size([32, 2])\n",
            "torch.Size([32, 64, 768])\n",
            "torch.Size([32, 2])\n",
            "torch.Size([32, 64, 768])\n",
            "torch.Size([32, 2])\n",
            "torch.Size([32, 64, 768])\n",
            "torch.Size([32, 2])\n",
            "torch.Size([32, 64, 768])\n",
            "torch.Size([32, 2])\n",
            "torch.Size([32, 64, 768])\n",
            "torch.Size([32, 2])\n",
            "torch.Size([32, 64, 768])\n",
            "torch.Size([32, 2])\n",
            "torch.Size([32, 64, 768])\n",
            "torch.Size([4, 2])\n",
            "torch.Size([4, 64, 768])\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2PBa_UklqKw",
        "outputId": "8d4b4970-b0b8-45d3-edde-b8ea94ae2d54"
      },
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive samples: 354 of 516 (68.60%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBaovkgYlysZ",
        "outputId": "098c98d3-f638-4583-ed39-1b96599598ff"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  \n",
        "  # Calculate and store the coef for this batch.  \n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
        "  matthews_set.append(matthews)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdgjQo76l288",
        "outputId": "ade421b7-76c6-4446-d14a-5362cc75f2f7"
      },
      "source": [
        "matthews_set"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.049286405809014416,\n",
              " -0.21684543705982773,\n",
              " 0.4732058754737091,\n",
              " 0.30508307783296046,\n",
              " 0.4133804997216296,\n",
              " 0.7410010097502685,\n",
              " 0.4547940268270977,\n",
              " 0.0,\n",
              " 0.9165151389911681,\n",
              " 0.6952687917708212,\n",
              " 0.9229582069908973,\n",
              " 0.647150228929434,\n",
              " 0.8749672939989046,\n",
              " 0.8320502943378436,\n",
              " 0.1794871794871795,\n",
              " 0.7229437229437229,\n",
              " 0.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYtOFHTLl82e",
        "outputId": "29655bc0-fff0-4104-cdca-99d51838f3d9"
      },
      "source": [
        "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('MCC: %.3f' % mcc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MCC: 0.524\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s18fKh3jnS3P"
      },
      "source": [
        "save and load the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnfZn00PabY2"
      },
      "source": [
        "\n",
        "### NEW YORK TIMES\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGMuGuMiQJ20"
      },
      "source": [
        "Load NewYorkTimes dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oKk36uias91",
        "outputId": "c1aced7f-bf82-4af3-df91-72bb06b1406a"
      },
      "source": [
        "#preload functions and packages\n",
        "# to check if the GPU is ready to use\n",
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vfa7zHjoay9s",
        "outputId": "2c54cc86-1461-45c6-92b8-8c15ad436799"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmdt5cWia06Y",
        "outputId": "31856a47-5fce-4b56-ec12-4add4e04be5f"
      },
      "source": [
        "!pip install transformers\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.8.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNbQif_HnVMo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99b7c5cc-6ec1-4dec-d420-6d9a039fc475"
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"./small_NYTimes.csv\", header=None,skiprows=1, names=['title', 'content', 'label'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "print(df.shape)\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)\n",
        "df = df.iloc[1:101]\n",
        "print(df.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 1,001\n",
            "\n",
            "(1001, 3)\n",
            "(100, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_N7KqgFAWY6m"
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = df.content.values\n",
        "labels = df.label.values"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNWOPVLoWph7",
        "outputId": "ce483037-a212-451d-a962-f10a75d477c6"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suJwoBDgWuq_",
        "outputId": "84c05649-d8bd-4a21-e70d-a5a5332d5e92"
      },
      "source": [
        "\n",
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  WASHINGTON  On Friday, Representative John Lewis, Democrat of Georgia, declared that he did not view Donald J. Trump as a legitimate president. Mr. Lewis, an icon of the civil rights movement, said he planned to boycott the inauguration, the first he will skip in three decades. On Saturday, Mr. Trump hit back. Congressman John Lewis should spend more time on fixing and helping his district, which is in horrible shape and falling apart (not to mention crime infested) rather than falsely complaining about the election results, Mr. Trump said in a pair of early morning Twitter posts. All talk, talk, talk  no action or results, he added. Sad! While some questioned Mr. Lewis s assertion, many others expressed indignation about Mr. Trump s outburst, pointing out the unseemliness of attacking a civil rights leader on the eve of Martin Luther King Jr. Day. Mr. Lewis was one of the original Freedom Riders, beaten by police officers while marching from Selma to Montgomery in Alabama. Others ridiculed Mr. Trump s characterization of Mr. Lewis s district, which is majority African-American and encompasses three-quarters of Atlanta, as horrible, falling apart and crime infested. In fact, Georgia s Fifth Congressional District includes parts of wealthy areas like Buckhead the world s busiest airport, Hartsfield-Jackson the Centers for Disease Control and Prevention and the Georgia Institute of Technology. Some pointed out that fighting with Mr. Lewis distracted attention from a Senate investigation, announced the day before, that will look at possible contacts between Mr. Trump s campaign team and Russia. In addition, Mr. Trump s poll numbers have slipped into uncharted depths for an incoming president, with a Gallup poll released on Friday finding that about half of Americans disapprove of Mr. Trump s transition effort. Mr. Trump s feud with Mr. Lewis carried echoes of his attacks on Khizr and Ghazala Khan, the Pakistani-American parents of an American soldier killed in Iraq, after Mr. Khan spoke out against Mr. Trump at the Democratic National Convention. Those attacks were widely viewed to have backfired, and Mr. Trump later modulated his words about the Khans. Mr. Trump himself has experience questioning a president s legitimacy. He was instrumental in sowing doubts about President Obama s birthplace. Mr. Lewis, who is 76 and was first elected to Congress in 1987, is one of the few genuinely historic figures on Capitol Hill, revered by Democrats and Republicans alike. Allies of Senator Jeff Sessions, Republican of Alabama and Mr. Trump s nominee for attorney general, circulated pictures of him linking arms with Mr. Lewis at the 50th anniversary of the Selma march to fend off accusations that Mr. Sessions was a racist. Nevertheless, Mr. Lewis testified against Mr. Sessions, declaring, We need someone as attorney general who s going to look out for all of us, and not just some of us. A few critics, including David Axelrod, a former senior adviser to Mr. Obama, said they disagreed with Mr. Lewis s statement that Mr. Trump was not legitimate, which he made in an interview with Chuck Todd of NBC News and which will be broadcast on Meet the Press on Sunday. Still, Mr. Axelrod said of Mr. Lewis: I honor the man he is. Honesty integrity courage  these are qualities you can t buy. In his interview with Mr. Todd, Mr. Lewis said he believed that the Russians had delivered the election to Mr. Trump. You know, I believe in forgiveness, he said. I believe in trying to work with people. It will be hard. It s going to be very difficult. I don t see this president-elect as a legitimate president. Mr. Lewis is one of a handful of Democratic members of Congress who have announced that they will boycott the inauguration on Friday. Others include Barbara Lee of California, Earl Blumenauer of Oregon, Katherine Clark of Massachusetts and Luis Gutirrez of Illinois.\n",
            "Tokenized:  ['washington', '', 'on', 'friday', ',', 'representative', 'john', 'lewis', ',', 'democrat', 'of', 'georgia', ',', 'declared', 'that', 'he', 'did', 'not', 'view', 'donald', 'j', '.', 'trump', 'as', 'a', '', 'legitimate', 'president', '.', '', 'mr', '.', 'lewis', ',', 'an', 'icon', 'of', 'the', 'civil', 'rights', 'movement', ',', 'said', 'he', 'planned', 'to', 'boycott', 'the', 'inauguration', ',', 'the', 'first', 'he', 'will', 'skip', 'in', 'three', 'decades', '.', 'on', 'saturday', ',', 'mr', '.', 'trump', 'hit', 'back', '.', '', 'congressman', 'john', 'lewis', 'should', 'spend', 'more', 'time', 'on', 'fixing', 'and', 'helping', 'his', 'district', ',', 'which', 'is', 'in', 'horrible', 'shape', 'and', 'falling', 'apart', '(', 'not', 'to', 'mention', 'crime', 'in', '##fest', '##ed', ')', 'rather', 'than', 'falsely', 'complaining', 'about', 'the', 'election', 'results', ',', '', 'mr', '.', 'trump', 'said', 'in', 'a', 'pair', 'of', 'early', 'morning', 'twitter', 'posts', '.', '', 'all', 'talk', ',', 'talk', ',', 'talk', '', 'no', 'action', 'or', 'results', ',', '', 'he', 'added', '.', '', 'sad', '!', '', 'while', 'some', 'questioned', 'mr', '.', 'lewis', 's', 'assertion', ',', 'many', 'others', 'expressed', 'ind', '##ign', '##ation', 'about', 'mr', '.', 'trump', 's', 'outburst', ',', 'pointing', 'out', 'the', 'un', '##see', '##ml', '##iness', 'of', 'attacking', 'a', 'civil', 'rights', 'leader', 'on', 'the', 'eve', 'of', 'martin', 'luther', 'king', 'jr', '.', 'day', '.', 'mr', '.', 'lewis', 'was', 'one', 'of', 'the', 'original', 'freedom', 'riders', ',', 'beaten', 'by', 'police', 'officers', 'while', 'marching', 'from', 'selma', 'to', 'montgomery', 'in', 'alabama', '.', 'others', 'rid', '##ic', '##uled', 'mr', '.', 'trump', 's', 'characterization', 'of', 'mr', '.', 'lewis', 's', 'district', ',', 'which', 'is', 'majority', 'african', '-', 'american', 'and', 'encompasses', 'three', '-', 'quarters', 'of', 'atlanta', ',', 'as', '', 'horrible', ',', '', '', 'falling', 'apart', '', 'and', '', 'crime', 'in', '##fest', '##ed', '.', '', 'in', 'fact', ',', 'georgia', 's', 'fifth', 'congressional', 'district', 'includes', 'parts', 'of', 'wealthy', 'areas', 'like', 'buck', '##head', 'the', 'world', 's', 'busiest', 'airport', ',', 'hart', '##sfield', '-', 'jackson', 'the', 'centers', 'for', 'disease', 'control', 'and', 'prevention', 'and', 'the', 'georgia', 'institute', 'of', 'technology', '.', 'some', 'pointed', 'out', 'that', 'fighting', 'with', 'mr', '.', 'lewis', 'distracted', 'attention', 'from', 'a', 'senate', 'investigation', ',', 'announced', 'the', 'day', 'before', ',', 'that', 'will', 'look', 'at', 'possible', 'contacts', 'between', 'mr', '.', 'trump', 's', 'campaign', 'team', 'and', 'russia', '.', 'in', 'addition', ',', 'mr', '.', 'trump', 's', 'poll', 'numbers', 'have', 'slipped', 'into', 'un', '##cha', '##rted', 'depths', 'for', 'an', 'incoming', 'president', ',', 'with', 'a', 'gall', '##up', 'poll', 'released', 'on', 'friday', 'finding', 'that', 'about', 'half', 'of', 'americans', 'di', '##sa', '##pp', '##rove', 'of', 'mr', '.', 'trump', 's', 'transition', 'effort', '.', 'mr', '.', 'trump', 's', 'feud', 'with', 'mr', '.', 'lewis', 'carried', 'echoes', 'of', 'his', 'attacks', 'on', 'k', '##hi', '##z', '##r', 'and', 'g', '##ha', '##zal', '##a', 'khan', ',', 'the', 'pakistani', '-', 'american', 'parents', 'of', 'an', 'american', 'soldier', 'killed', 'in', 'iraq', ',', 'after', 'mr', '.', 'khan', 'spoke', 'out', 'against', 'mr', '.', 'trump', 'at', 'the', 'democratic', 'national', 'convention', '.', 'those', 'attacks', 'were', 'widely', 'viewed', 'to', 'have', 'back', '##fire', '##d', ',', 'and', 'mr', '.', 'trump', 'later', 'mod', '##ulated', 'his', 'words', 'about', 'the', 'khan', '##s', '.', 'mr', '.', 'trump', 'himself', 'has', 'experience', 'questioning', 'a', 'president', 's', 'legitimacy', '.', 'he', 'was', 'instrumental', 'in', 'so', '##wing', 'doubts', 'about', 'president', 'obama', 's', 'birthplace', '.', 'mr', '.', 'lewis', ',', 'who', 'is', '76', 'and', 'was', 'first', 'elected', 'to', 'congress', 'in', '1987', ',', 'is', 'one', 'of', 'the', 'few', 'genuinely', 'historic', 'figures', 'on', 'capitol', 'hill', ',', 'revered', 'by', 'democrats', 'and', 'republicans', 'alike', '.', 'allies', 'of', 'senator', 'jeff', 'sessions', ',', 'republican', 'of', 'alabama', 'and', 'mr', '.', 'trump', 's', 'nominee', 'for', 'attorney', 'general', ',', 'circulated', 'pictures', 'of', 'him', 'linking', 'arms', 'with', 'mr', '.', 'lewis', 'at', 'the', '50th', 'anniversary', 'of', 'the', 'selma', 'march', 'to', 'fen', '##d', 'off', 'accusations', 'that', 'mr', '.', 'sessions', 'was', 'a', 'racist', '.', 'nevertheless', ',', 'mr', '.', 'lewis', 'testified', 'against', 'mr', '.', 'sessions', ',', 'declaring', ',', '', 'we', 'need', 'someone', 'as', 'attorney', 'general', 'who', 's', 'going', 'to', 'look', 'out', 'for', 'all', 'of', 'us', ',', 'and', 'not', 'just', 'some', 'of', 'us', '.', '', 'a', 'few', 'critics', ',', 'including', 'david', 'axel', '##rod', ',', 'a', 'former', 'senior', 'adviser', 'to', 'mr', '.', 'obama', ',', 'said', 'they', 'disagreed', 'with', 'mr', '.', 'lewis', 's', 'statement', 'that', 'mr', '.', 'trump', 'was', 'not', 'legitimate', ',', 'which', 'he', 'made', 'in', 'an', 'interview', 'with', 'chuck', 'todd', 'of', 'nbc', 'news', 'and', 'which', 'will', 'be', 'broadcast', 'on', '', 'meet', 'the', 'press', '', 'on', 'sunday', '.', 'still', ',', 'mr', '.', 'axel', '##rod', 'said', 'of', 'mr', '.', 'lewis', ':', '', 'i', 'honor', 'the', 'man', 'he', 'is', '.', 'honesty', 'integrity', 'courage', '', 'these', 'are', 'qualities', 'you', 'can', 't', 'buy', '.', '', 'in', 'his', 'interview', 'with', 'mr', '.', 'todd', ',', 'mr', '.', 'lewis', 'said', 'he', 'believed', 'that', 'the', 'russians', 'had', 'delivered', 'the', 'election', 'to', 'mr', '.', 'trump', '.', '', 'you', 'know', ',', 'i', 'believe', 'in', 'forgiveness', ',', '', 'he', 'said', '.', '', 'i', 'believe', 'in', 'trying', 'to', 'work', 'with', 'people', '.', 'it', 'will', 'be', 'hard', '.', 'it', 's', 'going', 'to', 'be', 'very', 'difficult', '.', 'i', 'don', 't', 'see', 'this', 'president', '-', 'elect', 'as', 'a', 'legitimate', 'president', '.', '', 'mr', '.', 'lewis', 'is', 'one', 'of', 'a', 'handful', 'of', 'democratic', 'members', 'of', 'congress', 'who', 'have', 'announced', 'that', 'they', 'will', 'boycott', 'the', 'inauguration', 'on', 'friday', '.', 'others', 'include', 'barbara', 'lee', 'of', 'california', ',', 'earl', 'blu', '##men', '##auer', 'of', 'oregon', ',', 'katherine', 'clark', 'of', 'massachusetts', 'and', 'luis', 'gutierrez', 'of', 'illinois', '.']\n",
            "Token IDs:  [2899, 1517, 2006, 5958, 1010, 4387, 2198, 4572, 1010, 7672, 1997, 4108, 1010, 4161, 2008, 2002, 2106, 2025, 3193, 6221, 1046, 1012, 8398, 2004, 1037, 1523, 11476, 2343, 1012, 1524, 2720, 1012, 4572, 1010, 2019, 12696, 1997, 1996, 2942, 2916, 2929, 1010, 2056, 2002, 3740, 2000, 17757, 1996, 17331, 1010, 1996, 2034, 2002, 2097, 13558, 1999, 2093, 5109, 1012, 2006, 5095, 1010, 2720, 1012, 8398, 2718, 2067, 1012, 1523, 12295, 2198, 4572, 2323, 5247, 2062, 2051, 2006, 15887, 1998, 5094, 2010, 2212, 1010, 2029, 2003, 1999, 9202, 4338, 1998, 4634, 4237, 1006, 2025, 2000, 5254, 4126, 1999, 14081, 2098, 1007, 2738, 2084, 23123, 17949, 2055, 1996, 2602, 3463, 1010, 1524, 2720, 1012, 8398, 2056, 1999, 1037, 3940, 1997, 2220, 2851, 10474, 8466, 1012, 1523, 2035, 2831, 1010, 2831, 1010, 2831, 1517, 2053, 2895, 2030, 3463, 1010, 1524, 2002, 2794, 1012, 1523, 6517, 999, 1524, 2096, 2070, 8781, 2720, 1012, 4572, 1055, 23617, 1010, 2116, 2500, 5228, 27427, 23773, 3370, 2055, 2720, 1012, 8398, 1055, 27719, 1010, 7302, 2041, 1996, 4895, 19763, 19968, 9961, 1997, 7866, 1037, 2942, 2916, 3003, 2006, 1996, 6574, 1997, 3235, 9678, 2332, 3781, 1012, 2154, 1012, 2720, 1012, 4572, 2001, 2028, 1997, 1996, 2434, 4071, 8195, 1010, 7854, 2011, 2610, 3738, 2096, 10998, 2013, 28112, 2000, 8482, 1999, 6041, 1012, 2500, 9436, 2594, 18696, 2720, 1012, 8398, 1055, 23191, 1997, 2720, 1012, 4572, 1055, 2212, 1010, 2029, 2003, 3484, 3060, 1011, 2137, 1998, 13974, 2093, 1011, 7728, 1997, 5865, 1010, 2004, 1523, 9202, 1010, 1524, 1523, 4634, 4237, 1524, 1998, 1523, 4126, 1999, 14081, 2098, 1012, 1524, 1999, 2755, 1010, 4108, 1055, 3587, 7740, 2212, 2950, 3033, 1997, 7272, 2752, 2066, 10131, 4974, 1996, 2088, 1055, 20530, 3199, 1010, 7530, 15951, 1011, 4027, 1996, 6401, 2005, 4295, 2491, 1998, 9740, 1998, 1996, 4108, 2820, 1997, 2974, 1012, 2070, 4197, 2041, 2008, 3554, 2007, 2720, 1012, 4572, 11116, 3086, 2013, 1037, 4001, 4812, 1010, 2623, 1996, 2154, 2077, 1010, 2008, 2097, 2298, 2012, 2825, 10402, 2090, 2720, 1012, 8398, 1055, 3049, 2136, 1998, 3607, 1012, 1999, 2804, 1010, 2720, 1012, 8398, 1055, 8554, 3616, 2031, 5707, 2046, 4895, 7507, 17724, 11143, 2005, 2019, 14932, 2343, 1010, 2007, 1037, 26033, 6279, 8554, 2207, 2006, 5958, 4531, 2008, 2055, 2431, 1997, 4841, 4487, 3736, 9397, 17597, 1997, 2720, 1012, 8398, 1055, 6653, 3947, 1012, 2720, 1012, 8398, 1055, 13552, 2007, 2720, 1012, 4572, 3344, 17659, 1997, 2010, 4491, 2006, 1047, 4048, 2480, 2099, 1998, 1043, 3270, 16739, 2050, 4967, 1010, 1996, 9889, 1011, 2137, 3008, 1997, 2019, 2137, 5268, 2730, 1999, 5712, 1010, 2044, 2720, 1012, 4967, 3764, 2041, 2114, 2720, 1012, 8398, 2012, 1996, 3537, 2120, 4680, 1012, 2216, 4491, 2020, 4235, 7021, 2000, 2031, 2067, 10273, 2094, 1010, 1998, 2720, 1012, 8398, 2101, 16913, 8898, 2010, 2616, 2055, 1996, 4967, 2015, 1012, 2720, 1012, 8398, 2370, 2038, 3325, 11242, 1037, 2343, 1055, 22568, 1012, 2002, 2001, 6150, 1999, 2061, 9328, 13579, 2055, 2343, 8112, 1055, 14508, 1012, 2720, 1012, 4572, 1010, 2040, 2003, 6146, 1998, 2001, 2034, 2700, 2000, 3519, 1999, 3055, 1010, 2003, 2028, 1997, 1996, 2261, 15958, 3181, 4481, 2006, 9424, 2940, 1010, 23886, 2011, 8037, 1998, 10643, 11455, 1012, 6956, 1997, 5205, 5076, 6521, 1010, 3951, 1997, 6041, 1998, 2720, 1012, 8398, 1055, 9773, 2005, 4905, 2236, 1010, 17640, 4620, 1997, 2032, 11383, 2608, 2007, 2720, 1012, 4572, 2012, 1996, 12951, 5315, 1997, 1996, 28112, 2233, 2000, 21713, 2094, 2125, 13519, 2008, 2720, 1012, 6521, 2001, 1037, 16939, 1012, 6600, 1010, 2720, 1012, 4572, 14914, 2114, 2720, 1012, 6521, 1010, 13752, 1010, 1523, 2057, 2342, 2619, 2004, 4905, 2236, 2040, 1055, 2183, 2000, 2298, 2041, 2005, 2035, 1997, 2149, 1010, 1998, 2025, 2074, 2070, 1997, 2149, 1012, 1524, 1037, 2261, 4401, 1010, 2164, 2585, 18586, 14127, 1010, 1037, 2280, 3026, 11747, 2000, 2720, 1012, 8112, 1010, 2056, 2027, 18335, 2007, 2720, 1012, 4572, 1055, 4861, 2008, 2720, 1012, 8398, 2001, 2025, 11476, 1010, 2029, 2002, 2081, 1999, 2019, 4357, 2007, 8057, 6927, 1997, 6788, 2739, 1998, 2029, 2097, 2022, 3743, 2006, 1523, 3113, 1996, 2811, 1524, 2006, 4465, 1012, 2145, 1010, 2720, 1012, 18586, 14127, 2056, 1997, 2720, 1012, 4572, 1024, 1523, 1045, 3932, 1996, 2158, 2002, 2003, 1012, 16718, 11109, 8424, 1517, 2122, 2024, 11647, 2017, 2064, 1056, 4965, 1012, 1524, 1999, 2010, 4357, 2007, 2720, 1012, 6927, 1010, 2720, 1012, 4572, 2056, 2002, 3373, 2008, 1996, 12513, 2018, 5359, 1996, 2602, 2000, 2720, 1012, 8398, 1012, 1523, 2017, 2113, 1010, 1045, 2903, 1999, 17213, 1010, 1524, 2002, 2056, 1012, 1523, 1045, 2903, 1999, 2667, 2000, 2147, 2007, 2111, 1012, 2009, 2097, 2022, 2524, 1012, 2009, 1055, 2183, 2000, 2022, 2200, 3697, 1012, 1045, 2123, 1056, 2156, 2023, 2343, 1011, 11322, 2004, 1037, 11476, 2343, 1012, 1524, 2720, 1012, 4572, 2003, 2028, 1997, 1037, 9210, 1997, 3537, 2372, 1997, 3519, 2040, 2031, 2623, 2008, 2027, 2097, 17757, 1996, 17331, 2006, 5958, 1012, 2500, 2421, 6437, 3389, 1997, 2662, 1010, 4656, 14154, 3549, 21126, 1997, 5392, 1010, 9477, 5215, 1997, 4404, 1998, 6446, 20836, 1997, 4307, 1012]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XH6lWKfYkUq",
        "outputId": "19704c24-2257-418a-a713-8d2f29e4d6e7"
      },
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "MAX_LEN = 128\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = MAX_LEN,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2132: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  WASHINGTON  On Friday, Representative John Lewis, Democrat of Georgia, declared that he did not view Donald J. Trump as a legitimate president. Mr. Lewis, an icon of the civil rights movement, said he planned to boycott the inauguration, the first he will skip in three decades. On Saturday, Mr. Trump hit back. Congressman John Lewis should spend more time on fixing and helping his district, which is in horrible shape and falling apart (not to mention crime infested) rather than falsely complaining about the election results, Mr. Trump said in a pair of early morning Twitter posts. All talk, talk, talk  no action or results, he added. Sad! While some questioned Mr. Lewis s assertion, many others expressed indignation about Mr. Trump s outburst, pointing out the unseemliness of attacking a civil rights leader on the eve of Martin Luther King Jr. Day. Mr. Lewis was one of the original Freedom Riders, beaten by police officers while marching from Selma to Montgomery in Alabama. Others ridiculed Mr. Trump s characterization of Mr. Lewis s district, which is majority African-American and encompasses three-quarters of Atlanta, as horrible, falling apart and crime infested. In fact, Georgia s Fifth Congressional District includes parts of wealthy areas like Buckhead the world s busiest airport, Hartsfield-Jackson the Centers for Disease Control and Prevention and the Georgia Institute of Technology. Some pointed out that fighting with Mr. Lewis distracted attention from a Senate investigation, announced the day before, that will look at possible contacts between Mr. Trump s campaign team and Russia. In addition, Mr. Trump s poll numbers have slipped into uncharted depths for an incoming president, with a Gallup poll released on Friday finding that about half of Americans disapprove of Mr. Trump s transition effort. Mr. Trump s feud with Mr. Lewis carried echoes of his attacks on Khizr and Ghazala Khan, the Pakistani-American parents of an American soldier killed in Iraq, after Mr. Khan spoke out against Mr. Trump at the Democratic National Convention. Those attacks were widely viewed to have backfired, and Mr. Trump later modulated his words about the Khans. Mr. Trump himself has experience questioning a president s legitimacy. He was instrumental in sowing doubts about President Obama s birthplace. Mr. Lewis, who is 76 and was first elected to Congress in 1987, is one of the few genuinely historic figures on Capitol Hill, revered by Democrats and Republicans alike. Allies of Senator Jeff Sessions, Republican of Alabama and Mr. Trump s nominee for attorney general, circulated pictures of him linking arms with Mr. Lewis at the 50th anniversary of the Selma march to fend off accusations that Mr. Sessions was a racist. Nevertheless, Mr. Lewis testified against Mr. Sessions, declaring, We need someone as attorney general who s going to look out for all of us, and not just some of us. A few critics, including David Axelrod, a former senior adviser to Mr. Obama, said they disagreed with Mr. Lewis s statement that Mr. Trump was not legitimate, which he made in an interview with Chuck Todd of NBC News and which will be broadcast on Meet the Press on Sunday. Still, Mr. Axelrod said of Mr. Lewis: I honor the man he is. Honesty integrity courage  these are qualities you can t buy. In his interview with Mr. Todd, Mr. Lewis said he believed that the Russians had delivered the election to Mr. Trump. You know, I believe in forgiveness, he said. I believe in trying to work with people. It will be hard. It s going to be very difficult. I don t see this president-elect as a legitimate president. Mr. Lewis is one of a handful of Democratic members of Congress who have announced that they will boycott the inauguration on Friday. Others include Barbara Lee of California, Earl Blumenauer of Oregon, Katherine Clark of Massachusetts and Luis Gutirrez of Illinois.\n",
            "Token IDs: tensor([  101,  2899,  1517,  2006,  5958,  1010,  4387,  2198,  4572,  1010,\n",
            "         7672,  1997,  4108,  1010,  4161,  2008,  2002,  2106,  2025,  3193,\n",
            "         6221,  1046,  1012,  8398,  2004,  1037,  1523, 11476,  2343,  1012,\n",
            "         1524,  2720,  1012,  4572,  1010,  2019, 12696,  1997,  1996,  2942,\n",
            "         2916,  2929,  1010,  2056,  2002,  3740,  2000, 17757,  1996, 17331,\n",
            "         1010,  1996,  2034,  2002,  2097, 13558,  1999,  2093,  5109,  1012,\n",
            "         2006,  5095,  1010,  2720,  1012,  8398,  2718,  2067,  1012,  1523,\n",
            "        12295,  2198,  4572,  2323,  5247,  2062,  2051,  2006, 15887,  1998,\n",
            "         5094,  2010,  2212,  1010,  2029,  2003,  1999,  9202,  4338,  1998,\n",
            "         4634,  4237,  1006,  2025,  2000,  5254,  4126,  1999, 14081,  2098,\n",
            "         1007,  2738,  2084, 23123, 17949,  2055,  1996,  2602,  3463,  1010,\n",
            "         1524,  2720,  1012,  8398,  2056,  1999,  1037,  3940,  1997,  2220,\n",
            "         2851, 10474,  8466,  1012,  1523,  2035,  2831,   102])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9OmBuNvY6Mf",
        "outputId": "4b7aab82-e13f-4562-abe1-85c5711fd72a"
      },
      "source": [
        "print('Max sentence length: ', max([len(sen) for sen in input_ids]))\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbJzelz_Y9C_"
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for\n",
        "# training\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 90% for training and 10% for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=2018, test_size=0.1)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyowECpNZEaH",
        "outputId": "0c7b996f-8f36-4ffa-9e80-d0111b91291b"
      },
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype \n",
        "# for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVeWrYXeZIzB"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "# batch_size = 32 change by ali \n",
        "batch_size = 32\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RCPybDFZMNS",
        "outputId": "3edee51b-b484-4443-b37a-5ae8aa1a9df9"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 12, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = True, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=12, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQKywWp0ZUVu",
        "outputId": "298644f7-89a5-4685-f93a-7c3a71658623"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                          (12, 768)\n",
            "classifier.bias                                                (12,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpDdenssZdA3"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32kJvjKSZfnx"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGkT45KfZkg6"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2y8R5lIKZnRt"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K044IkvSZrWw",
        "outputId": "d35d3547-e01b-4f59-c25e-0f8160e8a0f8"
      },
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    embedding_layers = []\n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "        # if step % 40 == 0 and not step == 0: changed by Ali\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        # print(len(outputs))\n",
        "        # print(outputs[0]) the loss\n",
        "        # print(len(outputs[1])) the batches\n",
        "        # print(len(outputs[2])) the embedding layers\n",
        "        # import numpy as np\n",
        "        # print(np.shape(outputs[2]))--->(13,)\n",
        "        # print(np.shape(outputs[2][1])) --->torch.Size([32, 64, 768]) the embedding in the layer one\n",
        "        # print(np.shape(outputs[2][2]))--->torch.Size([32, 64, 768]) the embedding in the layer two\n",
        "        # print(len(outputs[2][3]))\n",
        "        loss = outputs[0]\n",
        "        \n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 2.18\n",
            "  Training epcoh took: 0:00:02\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 1.80\n",
            "  Training epcoh took: 0:00:02\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 1.56\n",
            "  Training epcoh took: 0:00:02\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 1.42\n",
            "  Training epcoh took: 0:00:02\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuXdehgpeu8a",
        "outputId": "99591327-5c91-4020-c64b-851b26c7b98b"
      },
      "source": [
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "    #count = 0 # added by Ali\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        \n",
        "        logits = outputs[0]\n",
        "        # print(len(outputs))\n",
        "        # print(np.shape(outputs[1])) # all embedding layers data\n",
        "        # print(outputs[1][12]) # access to embedding vectors in layer 13\n",
        "        #count +=1 added by Ali\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "    #print(count)\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "TlHoRoWrfHHk",
        "outputId": "8aecfb74-c52f-4fc9-f2e4-6903fce36961"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHCXAK47gtMA",
        "outputId": "1f39a0fe-d09c-4bf8-8d37-cdf1087831d4"
      },
      "source": [
        "import pandas as pd\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "#the same as the maxlen we used in the encoder_plus function\n",
        "MAX_LEN = max([len(sen) for sen in input_ids])\n",
        "df = pd.read_csv(\"./small_NYTimes.csv\", header=None,skiprows=1, names=['title', 'content', 'label'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "print(df.shape)\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)\n",
        "df = df.iloc[1:101]\n",
        "print(df.shape)\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.content.values\n",
        "labels = df.label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask) \n",
        "\n",
        "# Convert to tensors.\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 100\n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 1,001\n",
            "\n",
            "(1001, 3)\n",
            "(100, 3)\n",
            "Number of test sentences: 100\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_V9AlX3_hNSX",
        "outputId": "d875d9ff-e2c4-4cbb-f845-de84c3e7d12a"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "  print(np.shape(outputs[1][12]))\n",
        "\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "print(np.shape(predictions[0][0]))\n",
        "print(np.shape(true_labels[0]))\n",
        "print('    DONE.')"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 100 test sentences...\n",
            "torch.Size([100, 128, 768])\n",
            "(12,)\n",
            "(100,)\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}